{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vid2e event generator\n",
    "\n",
    "In order to use this code, we need a new conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import esim_py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_events(events, resolution):\n",
    "    pos_events = events[events[:,-1]==1]\n",
    "    neg_events = events[events[:,-1]==-1]\n",
    "\n",
    "    image_pos = np.zeros(resolution[0]*resolution[1], dtype=\"uint8\")\n",
    "    image_neg = np.zeros(resolution[0]*resolution[1], dtype=\"uint8\")\n",
    "\n",
    "    np.add.at(image_pos, (pos_events[:,0]+pos_events[:,1]*resolution[1]).astype(\"int32\"), pos_events[:,-1]**2)\n",
    "    np.add.at(image_neg, (neg_events[:,0]+neg_events[:,1]*resolution[1]).astype(\"int32\"), neg_events[:,-1]**2)\n",
    "\n",
    "    image_rgb = np.stack(\n",
    "        [\n",
    "            image_pos.reshape(resolution),\n",
    "            image_neg.reshape(resolution),\n",
    "            np.zeros(resolution, dtype=\"uint8\")\n",
    "        ], -1\n",
    "    )\n",
    "\n",
    "    return image_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert video to event data\n",
    "\n",
    "Make sure your video is scaled to a rather low resolution, e.g.\n",
    "`ffmpeg -i input.avi -vf scale=320:240 output.avi`\n",
    "\n",
    "### preprocessing\n",
    "\n",
    "Put your video file into the folder `input` and run the following command.\n",
    "In the upsampling folder, run `python upsample.py --input_dir=input --output_dir=output`\n",
    "\n",
    "If you have a GPU, you can add `--device=cuda:0` to speed up the process, otherwise it can take a little while (try with a short video for the beginning). The frame images and timestamp file will be in the output directory.\n",
    "\n",
    "### frames to events\n",
    "\n",
    "Now you can run the esim code to simulate events from the video frame images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cp, Cn            = 0.1, 0.1\n",
    "refractory_period = 1e-4\n",
    "log_eps           = 1e-3\n",
    "use_log           = True\n",
    "\n",
    "input_directory = \"/home/user/output/\"\n",
    "image_folder    = input_directory + \"imgs/\"\n",
    "timestamps_file = input_directory + \"timestamps.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esim = esim_py.EventSimulator(Cp, Cn, refractory_period, log_eps, use_log)\n",
    "\n",
    "esim.setParameters(Cp, Cn, refractory_period, log_eps, use_log)\n",
    "\n",
    "events = esim.generateFromFolder(image_folder, timestamps_file)\n",
    "\n",
    "print(events.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our event data, ready for analysis! We have the events in a (N,4)-array, where the 4 coordinates are (x,y,t,+1/-1), giving us up or down events.\n",
    "\n",
    "### Visualize the events in a new video\n",
    "\n",
    "To visualise the events, we can make a new video, by aggregating the events that happened between the frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W             = 256, 240\n",
    "out_fps          = 30\n",
    "end_time         = events[-1,2]\n",
    "output_directory = \"/home/mirieder/event_video/\"\n",
    "pixel_augment    = 150\n",
    "\n",
    "def makeFrame(events, start, end, fname):\n",
    "    events1 = events[events[:,2] >= start]\n",
    "    events2 = events1[events1[:,2] < end]\n",
    "    \n",
    "    image_rgb = viz_events(events2, [H, W]) * pixel_augment\n",
    "    plt.imsave(fname, image_rgb)\n",
    "\n",
    "    return image_rgb\n",
    "\n",
    "num_frames = int(end_time*out_fps) + 1\n",
    "delta_t    = 1/out_fps\n",
    "\n",
    "for k in range(num_frames):\n",
    "    t_start = k*delta_t\n",
    "    makeFrame(events, t_start, t_start+delta_t, output_directory + \"frames/{0:04d}.png\".format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFMPEG command\n",
    "\n",
    "Run the following command in a different terminal to convert the frame images to a video file (adjust the file paths):\n",
    "`ffmpeg -y -framerate 30 -pattern_type glob -i \"/home/user/event_video/frames/*.png\" -c:v libx265 -x265-params lossless=1 /home/user/event_video/video.mp4`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
